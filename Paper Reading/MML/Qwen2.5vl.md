# 1 main contribution

1. window attention
2. dynamic FPS sampling
3. upgrade MRoPE in the temporal domain
4. data

# 2 Model Architecture

1. Large Language Model: Qwen2.5 LLM + MRoPE Aligned to Absolute Time(From 1D RoPE)
2. Vision Encoder:Redesigned vIt + 2D RoPE + Window Attention
3. MLP-based Vision-Language Merger