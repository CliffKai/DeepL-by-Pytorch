## MemGPT 架构组件 (MemGPT Architecture)

MemGPT 的设计核心是模拟操作系统的**内存管理单元 (MMU)**，将有限的 LLM 上下文窗口视为一种高速缓存 。

1. 内存层级 (Memory Hierarchy) 

| 内存层级 | 对应 OS 概念 | 特点与功能 |
| --- | --- | --- |
| **主上下文 (Main Context)** | 物理内存 (RAM) | <br>**LLM 唯一能直接看到的部分**。包括系统指令、工作上下文和消息队列。 |
| **召回存储 (Recall Storage)** | 磁盘/数据库 | 存储所有过往对话历史的完整日志。 |
| **归档存储 (Archival Storage)** | 磁盘/云存储 | 存储大规模静态知识库（如 Wikipedia）或被移出的长期记忆。|

2. 主上下文的三个区域 

* **系统指令 (System Instructions)**：**[只读]** 规定了代理的人设、任务目标以及如何管理内存的操作手册。

* **工作上下文 (Working Context)**：**[可读写]** 存储关于用户和代理当前状态的核心事实（如：用户对海鲜过敏），仅能通过函数调用修改 。

* **FIFO 队列 (FIFO Queue)**：**[动态更新]** 存储最近的消息流，包含用户输入、代理回复及系统状态警告 。

## 工作流程 (Operational Flow)

MemGPT 通过一个**“思考-行动-观察”**的闭环来实现其功能 。

1. 事件触发与队列管理 

* 当用户发送消息时，**队列管理器 (Queue Manager)** 将其存入 FIFO 队列 ；

* 系统自动计算当前 Token 总数 ；

* 如果空间充足，触发 LLM 推理；如果空间不足，系统会发送 **“内存压力 (Memory Pressure)”** 警告消息 ；

2. 自主函数执行 

LLM 在生成回复时，不仅生成文本，还会生成**函数调用 (Function Calls)** ：

* **读取操作**：调用 `archival_storage_search` 在数百万字文档中搜索特定信息 。

* **写入操作**：调用 `working_context.append` 更新关于用户的新发现 。

* **多步思考**：通过设置 `request_heartbeat=true`，LLM 可以在不等待用户回复的情况下连续执行多个操作（如：搜索 A -> 搜索 B -> 综合回答） 。

3. 上下文截断与总结 (Eviction & Summarization) 

当上下文窗口达到 100% 满额时：

1. **逐出 (Eviction)**：系统会自动移出最早的 50% 消息 ；

2. **总结 (Recursive Summary)**：被移出的消息会被总结为一段极其精炼的“递归摘要”，存放在队列的首部 ；

3. **持久化**：所有被移出的原始消息依然保留在**召回存储**中，随时可以通过搜索找回 。


## 核心函数示例 (Function Schema Example)

根据论文中的展示，MemGPT 常用以下逻辑管理其“意识” ：

```javascript
// 当 LLM 发现对话历史太长，需要保存重要事实时
working_context.append("用户的朋友叫 James，他们喜欢去 Six Flags");

// 当 LLM 需要回答一个它不记得的问题时
archival_storage.search("Nobel Prize physics 1901");

// 当 LLM 需要更新已有的信息时（如：用户分手了）
working_context.replace("男朋友 James", "前男友 James");

```
