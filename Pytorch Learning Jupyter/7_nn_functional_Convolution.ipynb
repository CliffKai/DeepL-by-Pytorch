{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef6cf46-4a00-4ba3-a350-e090180bda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里重点说明一下 torch.nn 和 torch.nn.functional 有何区别，下面用两者中的 convl2d 来举例说明：\n",
    "# torch.nn 是一个类，模型的参数 weight 和 bias 会自动注册，我们只需要给出其形状即可，weight 和 bias 会在后续网络的训练中自动更新优化\n",
    "# torch.nn.functional 只是一个函数，我们需要传入具体的 weight 和 bias 值，后续两者是否会随则会反向传播进行优化要看两者是否被加入到了参数列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c77507-5c4f-4525-a4ae-fe605710d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1eeb52-4978-4ab3-8790-dc478a99d4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "                      [0, 1, 2, 3, 1],\n",
    "                      [1, 2, 1, 0, 0],\n",
    "                      [5, 2, 3, 1, 1],\n",
    "                      [2, 1, 0, 1, 1]])\n",
    "kernel = torch.tensor([[1, 2, 1],\n",
    "                       [0, 1, 0],\n",
    "                       [2, 1, 0]])\n",
    "print(input.shape)\n",
    "print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e7157b-9604-4370-960c-9e600d828410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.reshape\n",
    "    # Args:\n",
    "    #     input (Tensor): the tensor to be reshaped    想要变换的张量\n",
    "    #     shape (tuple of int): the new shape          想要变换为的形状\n",
    "\n",
    "# torch.nn.functional.conv2d\n",
    "    # Args:\n",
    "    #     input,           输入，必须得是 (minibatch,in_channels,iH,iW) 的张量\n",
    "    #     weight,          卷积核（权重），必须得是 (out_channels,in_channels / groups,kH,kW) 的张量\n",
    "    #     bias=None,       偏置值，必须是 1 * out_channels 形状的张量\n",
    "    #     stride=1, \n",
    "    #     padding=0, \n",
    "    #     dilation=1, \n",
    "    #     groups=1\n",
    "input = torch.reshape(input, (1, 1, 5, 5))\n",
    "kernel = torch.reshape(kernel, (1, 1, 3, 3))\n",
    "print(input.shape)\n",
    "print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e7d30f-0ebc-411d-91d2-2113fa079508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[10, 12, 12],\n",
      "          [18, 16, 16],\n",
      "          [13,  9,  3]]]])\n"
     ]
    }
   ],
   "source": [
    "output1 = F.conv2d(input, kernel, stride = 1)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7274736-0bef-4c24-bee8-1dbaefe540ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "torch.Size([1])\n",
      "tensor([[[[11, 13, 13],\n",
      "          [19, 17, 17],\n",
      "          [14, 10,  4]]]])\n"
     ]
    }
   ],
   "source": [
    "# 这里必须使用类型转换\n",
    "# 使用 torch.tensor([...]) 创建 input 和 kernel 时，默认它们是 LongTensor（整型）,torch.ones 创建的默认是浮点类型\n",
    "# 而 F.conv2d 要求所有输入（包括 input、kernel、bias）类型必须 一致，通常是 float32（torch.float）\n",
    "# 虽然下面的示例采用了 conv2d_bias = conv2d_bias.long() 这样的转换，但是一般不推荐，这例子是做一个反面教材\n",
    "# 一般更推荐将所有传入参数都转换为浮点数，因为这样会让内部计算更快，有如下两种方法：\n",
    "# 方法1（更推荐）:在定义参数的时候直接明确为浮点数\n",
    "    # input = torch.tensor([[1, 2, 0, 3, 1],\n",
    "    #                       [0, 1, 2, 3, 1],\n",
    "    #                       [1, 2, 1, 0, 0],\n",
    "    #                       [5, 2, 3, 1, 1],\n",
    "    #                       [2, 1, 0, 1, 1]], dtype=torch.float)\n",
    "    \n",
    "    # kernel = torch.tensor([[1, 2, 1],\n",
    "    #                        [0, 1, 0],\n",
    "    #                        [2, 1, 0]], dtype=torch.float)\n",
    "\n",
    "# 方法2（不推荐）：\n",
    "    # input = input.float()\n",
    "    # kernel = kernel.float()\n",
    "conv2d_bias = torch.ones(1)\n",
    "conv2d_bias = conv2d_bias.long()\n",
    "print(conv2d_bias)\n",
    "print(conv2d_bias.shape)\n",
    "output2 = F.conv2d(input, kernel, bias = conv2d_bias, stride = 1)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eeaf0b2-fc77-4cbb-9fb9-578a53b1d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[10, 12],\n",
      "          [13,  3]]]])\n"
     ]
    }
   ],
   "source": [
    "# 关于stride\n",
    "output3 = F.conv2d(input, kernel, stride = 2)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43164be2-db5f-49ac-aebd-392df9b79fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  3,  4, 10,  8],\n",
      "          [ 5, 10, 12, 12,  6],\n",
      "          [ 7, 18, 16, 16,  8],\n",
      "          [11, 13,  9,  3,  4],\n",
      "          [14, 13,  9,  7,  4]]]])\n"
     ]
    }
   ],
   "source": [
    "# 关于padding\n",
    "output4 = F.conv2d(input, kernel, stride = 1, padding = 1)\n",
    "print(output4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (d2l && torch==1.12.0)",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
