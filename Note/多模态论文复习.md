这部分内容比较适合有一定多模态方向基础的人看。

# ITC

ITC：Image-Text Contrastive，其实就是有多个图文对，然后 1 图和多文算 InfoNCE，1 文和多图算 InfoNCE。

在一个 batch 中我们有：
$
{(I_1, T_1), (I_2, T_2), \dots, (I_N, T_N)}
$

**图像到文本中**：对每个图像$ ( I_i ) $，我们希望它的正确文本$ ( T_i ) $比其他所有$ ( T_j (j \ne i) ) $相似度更高。

损失：
$
L_{I \to T} = -\frac{1}{N}\sum_{i=1}^N
\log \frac{\exp(s_{ii})}{\sum_{j=1}^N \exp(s_{ij})}
$

也就是：

> 每张图像作为 query，batch 内的所有文本是候选集；
> 正样本：匹配文本 (T_i)，负样本：其他 (T_j)。

**文本到图像中**：对每个文本$ ( T_i ) $，希望它的匹配图像$ ( I_i ) $比其他$ ( I_j(j \ne i) ) $相似度更高。

损失：
$
L_{T \to I} = -\frac{1}{N}\sum_{i=1}^N
\log \frac{\exp(s_{ii})}{\sum_{j=1}^N \exp(s_{ji})}
$

也就是：

> 每段文本作为 query，batch 内的所有图像是候选集；
> 正样本：对应图 (I_i)，负样本：其他 (I_j)。

**双向合并（平均）**

$
L_{ITC} = \frac{1}{2} \big( L_{I \to T} + L_{T \to I} \big)
$

这就是所谓的 ITC

# CLIP

1. 对比学习；
2. Vision Encoder 与 Text Encoder 分别解码然后计算 ITC；
3. 学一个共享的图文语义空间，使得匹配的图文对在空间中靠得更近，不匹配的拉得更远。

# ALIGN

同 CLIP，但是训练数据从 4 亿图文对提升到了 13 亿。

