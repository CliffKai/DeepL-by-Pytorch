{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf954645-bd4e-43a5-b384-f6e6b497eb79",
   "metadata": {},
   "source": [
    "**注意** :由于pytorch版本的更新，现在 VGG16 所需的参数已经和以前不同，新版使用 weights 参数来代替旧版的 pretrained=True/False，所以内容以本案例为主即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e626ea-abcf-4f60-919a-88c75141639c",
   "metadata": {},
   "source": [
    "本节讲解现有网络模型的使用与修改   \n",
    "以 torchvision 中的 VGG16 为例   \n",
    "torchvision.models.vgg16\n",
    "### 参数1   \n",
    "&emsp;weights: Optional[torchvision.models.VGG16_Weights] = None   控制是否加载预训练权重，以及加载哪一组权重，常见设置参数如下图：     \n",
    "![VGG16_Weight](./images/VGG16_Weight.png)   \n",
    "**代码示例** :\n",
    "```python\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "# 加载预训练模型\n",
    "model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "# 不加载预训练权重\n",
    "model = vgg16(weights=None)\n",
    "```\n",
    "**注意** :   \n",
    "旧版本中的 pretrained=True 已不推荐使用，等价于：\n",
    "```python\n",
    "model = vgg16(pretrained=True)\n",
    "```\n",
    "### 参数2\n",
    "&emsp;progress: bool = True   当你第一次使用 weights=... 下载预训练模型时，是否在控制台显示下载进度条。   \n",
    "### 参数3\n",
    "&emsp;**kwargs   将其他关键字参数传给 torchvision.models.vgg.VGG 类的构造函数，用于更底层的定制，常见设置参数如下图：\n",
    "![VGG16_kwargs](./images/VGG16_kwargs.png) \n",
    "**代码示例** :\n",
    "```python\n",
    "# 这种方法会替换最后一层全连接输出层为 Linear(4096, 10)，常用于迁移学习场景（自定义数据集）\n",
    "model = vgg16(weights=None, num_classes=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6e969-a12a-403d-bc30-1f613c5c17ff",
   "metadata": {},
   "source": [
    "关于ImageNet数据集   \n",
    "ImageNet数据集需要去[ImageNet官网](https://www.image-net.org/download-images.php)下载，有问题的可以看这篇博客：[ImageNet数据集简介与下载详细步骤](https://blog.csdn.net/qq_36665989/article/details/119947229)   \n",
    "官网中说明需要的三个文件：\n",
    "Before using this class, it is required to download ImageNet 2012 dataset from here and place the files ILSVRC2012_devkit_t12.tar.gz and ILSVRC2012_img_train.tar or ILSVRC2012_img_val.tar based on split in the root directory.   \n",
    "作用分别如下：   \n",
    "![ImageNet_Files](./images/ImageNet_files.png)   \n",
    "**注意** ：不需要解压就可以使用   \n",
    "使用方法代码参考如下：   \n",
    "```python\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "root = \"/path/to/ImageNet\"\n",
    "train_set = ImageNet(root=root, split='train', transform=imagenet_transform)\n",
    "val_set = ImageNet(root=root, split='val', transform=imagenet_transform)\n",
    "```\n",
    "其中mean和std推荐使用代码示例中的值，因为这六个值都是根据 ImageNet 2012 数据集上统计得到的 RGB 通道的像素均值和标准差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d5b72f-74c2-48fe-9ce5-0e6a490b6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c4277c-1b00-4e5a-9853-08bb80d0e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 虽然土堆换了数据集，不再使用 ImageNet\n",
    "# 但是这里还是给出确定可以运行的代码，我在我的电脑上跑通了，tensorboard 中也正确加载出了图片，需要使用 ImageNet 小伙伴可以参考\n",
    "\n",
    "# imagenet_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(\n",
    "#         mean=[0.485, 0.456, 0.406],\n",
    "#         std=[0.229, 0.224, 0.225]\n",
    "#     )\n",
    "# ])\n",
    "# val_train = torchvision.datasets.ImageNet(\"../ImageNet/\",\n",
    "#                                           split = \"val\", transform = imagenet_transform)\n",
    "# dataloader = torch.utils.data.DataLoader(val_train, batch_size = 2)\n",
    "# step = 0\n",
    "# writer = SummaryWriter(\"../logs/15_Model_Pretrained\")\n",
    "# for data in dataloader:\n",
    "#     if step > 10:\n",
    "#         break\n",
    "#     imgs, targets = data\n",
    "#     writer.add_images(\"Image_Net\", imgs, step)\n",
    "#     step += 1\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972314d3-89ed-43c8-80de-9a387dc9e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_true = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "vgg16_false = models.vgg16(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d89922b-a8b3-436a-9d69-365756bf6d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cliffkai/Code/model_cache/hub\n"
     ]
    }
   ],
   "source": [
    "# 可以通过下面这条命令来查看模型的权重文件存放位置\n",
    "print(torch.hub.get_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47ab92f-50dd-4d3c-acfa-bd8628bbf5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print(vgg16_true)\n",
    "train_data = torchvision.datasets.CIFAR10(\"../datasets/CIFAR10/\", train = True, transform = torchvision.transforms.ToTensor(), download = True)\n",
    "# VGG16 是分1000类，而 CIFAR10 只有是个类别，有两种法：\n",
    "# 1.在模型后面添加一层，输入为1000，输出为10\n",
    "# 2.将模型的最后输出修改为10\n",
    "\n",
    "# 两种方法选择一种即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc213632-feaf-4d6f-8739-5a92a307f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    (add_linear): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  )\n",
      "  (add_linear): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 方法1:\n",
    "# 加到模型中\n",
    "vgg16_true.classifier.add_module('add_linear', nn.Linear(1000, 100))\n",
    "# 加到模型最后面\n",
    "vgg16_true.add_module('add_linear', nn.Linear(100, 10))\n",
    "\n",
    "print(vgg16_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509af9ef-6a77-4f7a-b90b-957f02c63c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 方法2:\n",
    "vgg16_false.classifier[6] = nn.Linear(4096, 10)\n",
    "print(vgg16_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43286d-bb2c-476c-bb07-e43431270993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
