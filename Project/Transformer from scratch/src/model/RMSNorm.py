
import torch
import torch.nn as nn

from jaxtyping import Float
from torch import Tensor

class RMSNorm(nn.Module):
    def __init__(
        self,
        d_model: int,
        eps: float = 1e-5,
        device: torch.device | str | None=None,
        dtype: torch.dtype | None=None,
    ):
        super().__init__()
        self.d_model = d_model
        self.eps = eps
        factory_kwargs = {"device":device, "dtype":dtype}
        self.weight = nn.Parameter(torch.ones((d_model), **factory_kwargs))

    def forward(self, x: Float[Tensor, "... d_model"]) -> Float[Tensor, "... d_model"]:
        in_dtype = x.dtype
        x = x.to(torch.float32)
        rrms = torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
        output = x * rrms * self.weight
        return output.to(in_dtype)

# test code
'''
import torch
from src.model.RMSNorm import RMSNorm  # å‡è®¾ä½ çš„æ–‡ä»¶è·¯å¾„ä¸º model/RMSNorm.py

# 1ï¸âƒ£ å›ºå®šéšæœºç§å­ï¼Œä¾¿äºå¤ç°
torch.manual_seed(0)

# 2ï¸âƒ£ åŸºæœ¬è¶…å‚æ•°
batch_size = 2
seq_len = 3
d_model = 8
eps = 1e-5

# 3ï¸âƒ£ æ„é€ å±‚ä¸è¾“å…¥ï¼ˆå¯åœ¨ CUDA ä¸Šæµ‹è¯•åŠç²¾åº¦ï¼‰
layer = RMSNorm(d_model=d_model, eps=eps)

x = torch.randn(batch_size, seq_len, d_model, requires_grad=True)
print("Input x shape:", x.shape)

# ğŸ§ª å¯é€‰ï¼šåœ¨ GPU ä¸Šæµ‹è¯• float16ï¼ˆè‹¥å¯ç”¨ï¼‰
if torch.cuda.is_available():
    device = torch.device("cuda")
    layer = layer.to(device)
    x = x.to(device).half().detach().requires_grad_(True)
    print("Running on CUDA with float16")

# 4ï¸âƒ£ å‰å‘è®¡ç®—
y = layer(x)
print("Output y shape:", y.shape)

# 5ï¸âƒ£ ä¸â€œæ‰‹å·¥â€RMSå½’ä¸€åŒ–å¯¹æ¯”ï¼ˆä¸ä¾èµ–ä»»ä½•å®˜æ–¹å®ç°ï¼‰
#    rrms = 1 / sqrt(mean(x^2) + eps)
#    y_ref = x * rrms * weight
with torch.no_grad():
    x32 = x.float()
    rrms = torch.rsqrt(x32.pow(2).mean(-1, keepdim=True) + eps)
    y_ref32 = x32 * rrms * layer.weight.float()
    y_ref = y_ref32.to(y.dtype)

print("All close to manual reference?", torch.allclose(y, y_ref, atol=1e-6 if y.dtype.is_floating_point else 1e-3))

# 6ï¸âƒ£ å½¢çŠ¶æ–­è¨€
assert y.shape == (batch_size, seq_len, d_model), "âŒ è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
print("âœ… å½¢çŠ¶æ£€æŸ¥é€šè¿‡ã€‚")

# 7ï¸âƒ£ é›¶è¾“å…¥æ•°å€¼ç¨³å®šæ€§ï¼ˆåº”è¾“å‡ºå…¨ 0ï¼‰
with torch.no_grad():
    x_zero = torch.zeros_like(x)
    y_zero = layer(x_zero)
    assert torch.count_nonzero(y_zero) == 0, "âŒ é›¶è¾“å…¥æ—¶è¾“å‡ºåº”å…¨ 0"
print("âœ… é›¶è¾“å…¥ç¨³å®šæ€§é€šè¿‡ã€‚")

# 8ï¸âƒ£ åå‘ä¼ æ’­æ£€æŸ¥ï¼ˆæƒé‡ä¸è¾“å…¥å‡åº”æœ‰æ¢¯åº¦ï¼‰
loss = y.sum()
loss.backward()
assert layer.weight.grad is not None, "âŒ æƒé‡æ²¡æœ‰æ¢¯åº¦"
assert x.grad is not None, "âŒ è¾“å…¥æ²¡æœ‰æ¢¯åº¦"
print("âœ… åå‘ä¼ æ’­æ£€æŸ¥é€šè¿‡ã€‚")
'''
