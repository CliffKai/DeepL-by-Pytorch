# 一、打补丁法

以MAE为例：

- 基于 ViT + BERT：
1. 遮住更多的图片块：另类的数据增强
- 好处：训练到1600轮的时候模型任然在提升
- 坏处：训练非常慢
- 改进：做一些别的数据增强，使得训练不需要花那么大的时间
2. 主干网络架构是ViT
- 改进：可以考虑用一些新的模型替换 ViT 来看看效果
3. 回到BERT：BERT的损失函数有两个，一个是完形填空，一个是句子对的匹配
- 改进：增加额外的损失函数，e.g.，contrastive learning
4. 编码时只处理没遮住的
5. 用 Transformer 来输出（解码）

当有新的想法的时候要去做实验验证，可能不易i的那个效果很好，但是可能也会受到新的启发。







