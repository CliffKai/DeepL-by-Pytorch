{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2265223f-19e0-4a41-aeb5-f7bbab3113ef",
   "metadata": {},
   "source": [
    "# PyTorch 从零实现 Transformer\n",
    "\n",
    "## 目录\n",
    "\n",
    "1. Introduction\n",
    "2. Basic Components\n",
    "    1. Create Word Embeddings\n",
    "    2. Positional Encoding\n",
    "    3. Self Attention\n",
    "3. Encoder\n",
    "4. Decoder\n",
    "5. Testing\n",
    "6. Some useful resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279e941-6e2d-43d9-8313-66cb5b7c1a60",
   "metadata": {},
   "source": [
    "# 1.Introduction\n",
    "\n",
    "本内容如何使用 Pytorch 从零开始实现 Transformer 架构，想要深入了解 Transformer 原理推荐下面内容：\n",
    "\n",
    "1. [我自己写的笔记](https://github.com/CliffKai/DeepL-by-Pytorch/blob/master/Paper%20Reading/NLP/Transformer.md)\n",
    "2. [Transformer 论文:Attention is All you Need](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)\n",
    "3. [李沐老师的d2l](https://zh-v2.d2l.ai/chapter_attention-mechanisms/index.html)\n",
    "4. [Jay Alammar 的 Blog](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "![Figure_1](../../images/Transformer_from_scratch_Figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c170b2-7212-4c9a-9c4e-6c79cc319b12",
   "metadata": {},
   "source": [
    "# 2.Basic Components\n",
    "\n",
    "首先我们导入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b58a6b-21fe-4fce-82e7-d723ed524ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math,copy,re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(\"ignore\")\n",
    "print(torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a67790-afd9-4fba-a83c-7c4717d93db0",
   "metadata": {},
   "source": [
    "## 2.1 Create Word Embeddings\n",
    "\n",
    "首先我们需要将输入序列中的每个词转化为一个嵌入向量，将离散的词语表示转换为具有语义意义的稠密向量表示，以便神经网络可以理解、处理和学习语言中的词语之间的关系。\n",
    "\n",
    "这里我们假设每个嵌入向量的维度是 512，构建一个大小为 100 的词汇表，嵌入矩阵为 100 × 512。也就是说每个词会被编码为 512 维的一个向量，并且这个向量是可学习的。\n",
    "\n",
    "举个例子：假设我们的 batch_size = 32，每个 batch_size 的长度为 10 个词，那我们的输出向量则为 32x10x512。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e130311-cb7a-4c4c-85f3-6797b9342dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有 PyTorch 的模型、层都需要继承自 nn.Module\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size:词汇表大小\n",
    "            embed_dim:词嵌入维度\n",
    "        \"\"\"\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x:输入的词索引张量，shape 通常为 [batch_size, seq_len]\n",
    "        Return:\n",
    "            out:词向量张量，形状为 [batch_size, seq_len, embed_dim]\n",
    "        \"\"\"\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5950143-ba91-4a72-8158-712a4d685e4f",
   "metadata": {},
   "source": [
    "## 2.2 Positional Encoding\n",
    "\n",
    "Transformer 自身无法感知顺序，所以需要位置编码来让模型知道每个词所在的位置。\n",
    "\n",
    "此处使用原论文中的 Sinusoidal Positional Encoding（正余弦位置编码）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489ab5b2-5605-4cd1-8299-bea483982114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len, embed_model_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_seq_len:最长支持的序列长度\n",
    "            embed_model_dim:嵌入向量的维度\n",
    "        \"\"\"\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.embed_dim = embed_model_dim\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, slef.embed_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, self.embed_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/self.embed_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.embed_dim)))\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x:词嵌入后的张量，shape = [batch_size, seq_len, embed_dim]\n",
    "        Return:\n",
    "            x:加入了位置编码的词嵌入张量，shape = [batch_size, seq_len, embed_dim]\n",
    "        \"\"\"\n",
    "        # 防止位置编码影响太大，提高训练稳定性\n",
    "        x = x * math.sqrt(self.embed_dim)\n",
    "        seq_len = x.size(1)\n",
    "        # 使用 torch.autograd.Variable(..., requires_grad=False) 包裹是为了防止参与梯度计算\n",
    "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3415ae5-2edc-45c1-8063-178c24141683",
   "metadata": {},
   "source": [
    "## 2.3 Self Attention\n",
    "\n",
    "![MultiHeadAttention](../../images/Transformer_from_scratch_Figure_MultiHeadAttention.png)\n",
    "\n",
    "关于 Attention 的详细解释，请参照 Introduction 中的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180cf795-8485-43ef-a930-d30655ba3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_heads=8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim:输入维度，MultiHeadAttention 的输入维度必须和 Word Embedding 的输出维度一致\n",
    "            n_heads:头数，embed_dim 必须能被 n_heads 整除\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_heads = heads\n",
    "        self.single_head_dim = int(self.embed_dim / self.n_heads)\n",
    "\n",
    "        # 构造 qkv\n",
    "        self.qiery_matrix = nn.Linear(self.single_head_dim, self.single_head_dim, bias=False)\n",
    "        self.key_matrix = nn.Linear(self.single_dim, self.single_head_dim, bias=False)\n",
    "        self.value_amatrix = nn.Linear(self.single_dim, self.single_head_dim, bias=False)\n",
    "        self.out = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, key, query, value, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            key:key vector\n",
    "            query:query vector\n",
    "            value:value vector\n",
    "\n",
    "        Returns:\n",
    "            output vector from multihead attention\n",
    "        \"\"\"\n",
    "        batch_size = key.size(0)\n",
    "        seq_length = key.size(1)\n",
    "\n",
    "        seq_length_query = query.size(1)\n",
    "\n",
    "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406a185-c56e-4e7e-8dfd-32da8525a088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6238d-1641-4ca2-b31d-d214bcd9bf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenVLA(torch==2.2.0)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
