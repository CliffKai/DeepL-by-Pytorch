BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation

# Abstract

1. VLA 模型性能强大，但随着规模增大，其在内存受限的边缘设备上难以部署。
2. 现有 1-bit 量化在 LLM 中已验证有效，但尚未应用于 VLA 任务。
3. 本文提出 **BitVLA**：首个 **全参数三值化（{−1,0,1}）的 VLA 模型**，并结合 **蒸馏感知训练** 将视觉编码器压缩至 **1.58-bit**。
4. 在 **LIBERO 机器人操作基准** 上评估，BitVLA 在无大规模机器人预训练的情况下，依旧能在保持接近 SOTA 性能的同时，仅使用 **29.8% 的内存**，展示了在边缘设备部署的潜力。

# 1 Introduction

1. VLM 模型发展迅速，并逐渐扩展为 VLA 模型，使机器人具备理解视觉、语言并执行动作的能力，但其庞大规模导致在内存受限的机器人平台上部署困难。
2. 当前 1-bit/1.58-bit 量化在 LLM 中已被验证有效，能够大幅减少存储和推理开销，但尚未应用于 VLA 任务。
3. 本文提出 **BitVLA**：首个基于 **BitNet b1.58-2B4T** 的全参数三值化 VLA 模型，并通过 **蒸馏感知训练** 将视觉编码器压缩至 **1.58-bit（权重）+ 8-bit（激活）**。
4. 在 **LIBERO 基准** 上，BitVLA 即便未经过大规模机器人预训练，也能取得接近 **OpenVLA-OFT (INT4)** 的性能，但内存占用仅为其 **29.8%**，展现了在边缘设备上的潜力。

# 2 Related Work

## Ⅰ. Vision-Language-Action (VLA) models

近几年 **VLM 的进展**如何推动 **VLA 模型**的发展：

1. **RT 系列 \[ZYX+23, ORM+]**

   * 引入 **Open X-Embodiment (OXE)**：一个大规模标准化的机器人数据集。
   * 基于该数据集训练了 **RT-X**，一个通用型的机器人操作模型，能处理多种任务。

2. **OpenVLA \[KPK+24]**

   * 对 VLA 的设计空间进行了全面分析：从预训练架构、参数高效微调到部署策略。
   * **亮点**：完整开源了训练方法和预训练模型。

3. **RoboFlamingo \[LLZ+24]**

   * 利用预训练 VLM 来做单步视觉-语言推理。
   * 增加了 **policy head** 捕捉任务的时序信息。
   * 只需少量模仿学习（imitation learning）微调即可。

4. **OpenVLA-OFT \[KFL25]**

   * 针对机器人操作任务的微调进行了优化。
   * 方法：

     * **连续动作建模**
     * **并行解码**
     * **action chunking**（参考 \[ZKLF23, CFD+23] 的模仿学习方法）

5. **TinyVLA \[WZL+24]**

   * 使用更小的 **1.3B 参数 VLM backbone**。
   * 跳过大规模预训练，提高数据效率，降低计算开销。

6. **NORA \[HSH+25]**

   * 使用 **Qwen2.5-VL-3B \[BCL+25]** 作为 backbone。
   * 增强了 **FAST+ tokenizer** 以改进行动生成。
   * 在保持轻量的同时表现出较强竞争力。

**总结**：当前 **VLA 已经形成多个路线**：大规模预训练 (RT-X, OpenVLA)、轻量模型 (TinyVLA, NORA)、以及利用预训练 VLM 快速适配 (RoboFlamingo, OpenVLA-OFT)。


## Ⅱ. Native 1-bit models

 **1-bit / 1.58-bit LLM 的发展**：

1. **背景动机**

   * 深度学习社区越来越关注 **量化感知训练（QAT）** 和 **低比特推理**，因为可以减少内存占用和能耗，提高速度。

2. **代表性工作**

   * **\[WMD+23] BitNet**

     * 实证表明：随着参数规模增加，1-bit 和全精度模型的性能差距缩小。
   * **BitNet b1.58 \[MWM+24]**

     * 1.58-bit LLM 在 **3B 参数规模以上** 就能达到和全精度模型相当的性能。
     * 显著降低推理的 **内存占用、延迟和能耗**。
   * **OneBit \[XHY+24]**

     * 结合 **知识蒸馏** 来训练二值 LLM。
   * **bitnet.cpp \[WZS+25]**

     * 为 1-bit LLM 构建了优化的推理系统，尤其适合 **CPU 部署**，能耗和延迟都大幅降低。
   * **\[MWH+25]**

     * 训练了一个 **2B 参数三值 LLM**，性能接近主流开源 LLM。

3. **总结观点**

   * **1-bit 模型的低内存和低能耗优势**使它们特别适合边缘设备和机器人场景。
   * 但是：到目前为止，还没有系统地探索过 **1-bit 技术在 VLM/VLA 上的应用**。

# 3 BitVLA: 1-bit VLA

