Mem OS

## 1. Memory Storage
MemoryOS 将记忆划分为三个逻辑层级，以平衡信息的实时性、主题深度和长期一致性：
- 短期记忆 (STM)：存储实时对话数据。每一页（Page）包含查询、响应和时间戳。为了保证连贯性，它使用对话链 (Dialogue Chain) 机制，由 LLM 评估新内容与前文的语义关联性，确保上下文跟踪的一致性。
- 中期记忆 (MTM)：采用分段分页 (Segmented Paging) 架构。具有相同主题的对话页被归组为“段（Segment）”。通过语义和关键词相似度（$\mathcal{F}_{score}$）来确定页面是否属于某个特定主题段。
- 长期个人记忆 (LPM)：存储持久化的用户和智能体人格特征。
  - 用户侧：包含静态配置（姓名、性别等）、动态事实知识库（User KB）和演进的兴趣偏好（User Traits）。
  - 智能体侧：包含角色设定（Agent Profile）和在交互中发展的动态属性（Agent Traits）。

## 2. Memory Updating
系统通过特定的策略在不同层级间迁移和清理数据：
- STM 到 MTM：遵循先进先出 (FIFO) 原则。当 STM 队列达到最大容量（如 7 页）时，最旧的对话页将被迁移到 MTM 中相应的主题段。
- MTM 到 LPM：基于热度评分 (Heat Score) 机制。
  - 热度计算：综合考虑访问频率 ($N_{visit}$)、交互深度 ($L_{interaction}$) 和基于指数衰减的时间近时性 ($R_{recency}$)。
  - 迁移与淘汰：热度超过阈值（如 5）的段会被提取核心信息更新到 LPM 中。反之，当存储溢出时，热度最低的段会被驱逐。
- LPM 更新：通过 LLM 从高热度对话中自动提取 90 个维度的用户特质，实现人格的自主演进。

## 3. Retrieval & Generation
为了从庞大的记忆库中精准提取信息，MemoryOS 采用了精细的检索流程：
- 两阶段 MTM 检索：首先通过匹配得分筛选出前 $m$ 个候选主题段，然后再从这些段落中检索出语义最相关的 $k$ 个对话页。这种“由粗到细”的方法模拟了人类的记忆回溯。
- 全方位集成：在生成响应时，系统会整合 STM 的实时上下文、MTM 的历史对话细节以及 LPM 的人格背景信息，构建成最终的 Prompt。

## 4. 架构总结

1. 核心架构：三层存储模型
  MemoryOS 将记忆划分为三个物理/逻辑层级，模拟了从瞬时理想到永久知识的转化过程：
    - 短期记忆 (STM - Short-Term Memory)：
      - 存储单位：对话页 (Dialogue Page)。每一页包含 $Q$（问题）、$R$（回答）和 $T$（时间戳）。
      - 逻辑结构：对话链 (Dialogue Chain)。系统利用 LLM 实时评估当前对话与前文的语义相关性，如果相关则连入链条并更新“元摘要” (Metachain)，如果不相关则重置链条。
    - 中期记忆 (MTM - Mid-Term Memory)：
      - 存储架构：分段分页 (Segmented Paging)。受 OS 启发，将具有相同主题的对话页聚类为“段” (Segment)。
      - 管理机制：通过语义和关键词相似度（$\mathcal{F}_{score}$）决定新页面归属于哪个段。
    - 长期个人记忆 (LPM - Long-term Personal Memory)：
      - 组成部分：分为“用户人格”和“智能体人格”。
      - 内容：存储静态配置（如姓名、角色设定）、事实知识库（User KB）和动态演进的特质标签（User Traits）。
2. 四大核心模块及其运行机制
  整个系统由存储、更新、检索和生成四个模块协同工作：
    - 内存存储 (Storage)
    实现了上述的三层结构，确保了信息从“原始对话”到“主题摘要”再到“人格特质”的层级化存储。
    - 内存更新 (Updating) —— 动态迁移逻辑
    这是 MemoryOS 的精髓，模拟了内存页的置换和固化：
      - STM $\rightarrow$ MTM：采用 FIFO（先进先出） 策略。当 STM 队列满时，最旧的对话页被挤出并存入 MTM 对应的主题段。
      - MTM $\rightarrow$ LPM：基于 热度评分 (Heat Score)。
        - 热度由检索次数、交互深度和 **时间衰减（Recency）** 共同决定。
        - 高热度（Heat > 5）的段会被提取核心信息更新到 LPM，实现人格的自主演进。
        - 低热度的段在存储溢出时会被驱逐（删除）。
    - 内存检索 (Retrieval) —— 两阶段精准定位
    为了在海量历史中找到相关信息，系统在 MTM 层级采用了两阶段检索：
      - 第一步（段级）：根据查询 $Q$ 的向量匹配，找到前 $m$ 个相关的主题段。
      - 第二步（页级）：在选定的段内，检索语义最相关的 $k$ 个原始对话页。此外，系统还会同步检索 STM 的全部内容和 LPM 的人格信息。
    - 响应生成 (Generation)
    系统将检索到的三种内容（近期上下文、历史细节、人格特质）整合成一个增强的 Prompt 发送给 LLM。这保证了回复既符合当前的聊天逻辑，又能引用历史细节，且语气符合既定人设。

## 5. 机制优势总结

- 高效性：实验证明，相比于 MemGPT 或 A-Mem，MemoryOS 在提升性能的同时显著减少了 LLM 的调用次数和 Token 消耗。
- 连贯性：通过分段分页和对话链设计，即便在长时间跨度的对话中也能保持事实一致性。
- 个性化：LPM 模块确保了 AI 智能体能够记住用户的长期目标（如“减肥”）并在后续互动中主动提及。